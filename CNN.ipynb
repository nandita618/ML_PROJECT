{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed805c5c-2561-4839-975d-842862e992ab",
   "metadata": {},
   "source": [
    "IMPORT THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c92cb4-8991-49d5-b9b9-829ac31b295a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "599f99fb-214a-4883-a6a3-549e91d7b9d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39m__version__\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b4f564-5a0a-40fc-b9b1-28929266c255",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6ea31d7-d7f5-48b8-b818-a490d045f467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'dataset/training_set',  # this is the target directory\n",
    "        target_size=(64, 64),  # all images will be resized to 150x150\n",
    "        batch_size=32,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d39b755-c17e-4de1-b57f-fbcb074c5849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "test_set= train_datagen.flow_from_directory(\n",
    "        'dataset/test_set',  # this is the target directory\n",
    "        target_size=(64,64),  # all images will be resized to 150x150\n",
    "        batch_size=32,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214e9c7c-92c3-478f-9029-59b52fe1c293",
   "metadata": {},
   "source": [
    "INITIALISING THE CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30944f34-ddb5-4dd2-a9d6-836157c5b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ef791a-cce1-4aad-836b-e6b925dd99b2",
   "metadata": {},
   "source": [
    "step 1=CONVOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a7f3d9a-7d8f-4ade-88ce-1176256e3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f9b5e-ad12-4976-aad0-d35481fd59e1",
   "metadata": {},
   "source": [
    "STEP=3 POOLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a6cd309-345a-4b75-8aa1-39110213f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7641887d-afe2-417e-83d8-ad9fd90baf7f",
   "metadata": {},
   "source": [
    "ADDING A SECOND CONVOLUTION LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30767636-d5ec-4481-ad96-98e2e8deca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd43383-6b70-4a2b-ae95-6b91546d94a1",
   "metadata": {},
   "source": [
    "STEP=3 FLATTENING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20ce31a0-cb21-4963-9cdc-cb082ae63d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007dfc11-9f8e-4a70-b640-7ccad57e3ef0",
   "metadata": {},
   "source": [
    "FULL CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb09de7e-1055-4679-b4aa-4714d20f5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa4537-791d-49ec-a9d8-f2b30ad2b75f",
   "metadata": {},
   "source": [
    "OUTPUT LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbb91482-1136-44ef-ad01-eab21708562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16781d21-63e6-4d57-83d6-dab18bed267f",
   "metadata": {},
   "source": [
    "TRAINNING THE CNN\n",
    "COMPILING THE CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3acdb640-06d4-4e20-bf8a-554aa2e6f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b901a-fb6f-4697-96a0-6349d70236db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
